The traditional Word2Vec model has lead to significant improvements in the field of NLP, but has a limitation that good vector representations are not learned for: Rare words Words that are not seen in the training corpus This problem is more prominent in case of morphologically rich languages (e.g. German). To overcome these, we incorporated the information about the character n-grams that each word is made of into its vector representation and assess the performance of the vectors using intrinsic and extrinsic evaluation methods.  <br>
<br>
The following is the poster for this project: <br><br>
<iframe style="width:100%;height:500px;" src="posters/CS224NPoster.pdf"></iframe>